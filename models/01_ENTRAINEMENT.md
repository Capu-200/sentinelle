# üéì Entra√Ænement des Mod√®les ML

Guide complet pour entra√Æner et d√©ployer les mod√®les ML sur Google Cloud Run Jobs.

---

## üìã Vue d'Ensemble

L'entra√Ænement se fait en **4 √©tapes principales** :

1. **Pr√©paration des donn√©es** : Mapping PaySim ‚Üí Payon, split temporel
2. **Feature Engineering** : Calcul des features transactionnelles et historiques
3. **Entra√Ænement** : LightGBM (supervis√©) + IsolationForest (non supervis√©)
4. **D√©ploiement** : Upload vers Cloud Storage, versioning

**Temps estim√©** : ~30-45 minutes sur Cloud Run Jobs (8 vCPU, 8GB RAM)

---

## üöÄ Quick Start

### Entra√Ænement sur Google Cloud

```bash
cd models

# 1. D√©ployer le job
./scripts/deploy-training-job.sh \
  "sentinelle-485209" \
  "sentinelle-training" \
  "europe-west1" \
  "1.0.0"

# 2. Lancer l'entra√Ænement
./scripts/run-training-cloud.sh \
  "sentinelle-485209" \
  "sentinelle-training" \
  "europe-west1" \
  "1.0.0"

# 3. Suivre les logs
gcloud run jobs logs read sentinelle-training \
  --region=europe-west1 \
  --project=sentinelle-485209 \
  --limit=100
```

---

## üìä √âtape 1 : Pr√©paration des Donn√©es

### Mapping PaySim ‚Üí Payon

Le dataset PaySim doit √™tre mapp√© vers le format Payon pour l'entra√Ænement.

**Mapping principal** :
- `step` ‚Üí `created_at` (conversion en timestamp)
- `type` ‚Üí `transaction_type`
- `amount` ‚Üí `amount`
- `nameOrig` ‚Üí `source_wallet_id`
- `nameDest` ‚Üí `destination_wallet_id`
- `isFraud` ‚Üí `is_fraud` (label pour supervis√©)

**Code** : `src/data/preparation.py` ‚Üí `map_paysim_to_payon()`

**Exemple** :
```python
from src.data.preparation import map_paysim_to_payon

payon_df = map_paysim_to_payon(
    paysim_path=Path("Data/raw/paysim dataset.csv"),
    max_amount=None,  # Pas de filtrage
    output_path=Path("Data/processed/paysim_mapped.csv"),
)
```

### Split Temporel

**Important** : Split **temporel** (pas al√©atoire) pour √©viter le leakage.

**Ratio** : 70% train / 15% val / 15% test

**Code** : `src/data/preparation.py` ‚Üí `prepare_training_data()`

**Exemple** :
```python
from src.data.preparation import prepare_training_data

train_df, val_df, test_df = prepare_training_data(
    data_path=Path("Data/processed/paysim_mapped.csv"),
    train_ratio=0.7,
    val_ratio=0.15,
    test_ratio=0.15,
)
```

**Validation** : V√©rifie qu'il n'y a pas de leakage temporel (train.max < val.min < test.min)

---

## üîß √âtape 2 : Feature Engineering

### Features Transactionnelles

Features directement extraites de la transaction :

- `amount` : Montant de la transaction
- `log_amount` : log(1 + amount)
- `currency_is_pyc` : Bool√©en (currency == "PYC")
- `direction_outgoing` : 1 si outgoing, 0 sinon
- `hour_of_day` : Heure (0-23)
- `day_of_week` : Jour de la semaine (0-6)
- Encodage one-hot : `transaction_type`, `country`

**Code** : `src/features/extractor.py` ‚Üí `extract_transaction_features()`

### Features Historiques

Agr√©gats calcul√©s depuis l'historique des transactions :

**Fen√™tres temporelles** : `5m`, `1h`, `24h`, `7d`, `30d`

**Cl√©s d'agr√©gation** :
- Wallet source (`source_wallet_id`)
- Wallet destination (`destination_wallet_id`)
- Paire source‚Üídestination
- Utilisateur initiateur

**Exemples de features** :
- `src_tx_count_out_1h` : Nombre de transactions sortantes (1h)
- `src_tx_amount_mean_out_7d` : Montant moyen sortant (7j)
- `is_new_destination_30d` : Nouveau destinataire (30j)
- `src_unique_destinations_24h` : Nombre de destinataires uniques (24h)

**Total** : ~36 features historiques

**Code** : `src/features/aggregator.py` ‚Üí `compute_historical_aggregates()`

### Calcul des Features pour l'Entra√Ænement

**Mode parall√®le** (recommand√©) :

```python
from src.features.training import compute_features_parallel

features_df = compute_features_parallel(
    transactions_df=train_df,
    n_jobs=7,  # Nombre de processus parall√®les
    chunk_size=1000,
    verbose=True,
)
```

**Performance** : ~270-320 it/s sur M2 Pro (10 cores)

**Code** : `src/features/training.py` ‚Üí `compute_features_parallel()`

---

## ü§ñ √âtape 3 : Entra√Ænement des Mod√®les

### Mod√®le Supervis√© (LightGBM)

**Dataset** : PaySim (avec labels `is_fraud`)

**Objectif** : Apprendre √† d√©tecter la fraude depuis des exemples labelis√©s

**Configuration par d√©faut** :
```python
{
    "objective": "binary",
    "metric": "average_precision",  # PR-AUC
    "num_leaves": 31,
    "learning_rate": 0.05,
    "scale_pos_weight": auto,  # G√®re le d√©s√©quilibre
    "n_estimators": 1000,
    "early_stopping": 100,
}
```

**Gestion du d√©s√©quilibre** :
- `scale_pos_weight` calcul√© automatiquement
- Optimisation de PR-AUC (robuste aux classes rares)

**Code** : `src/models/supervised/train.py` ‚Üí `SupervisedModel`

**Exemple** :
```python
from src.models.supervised.train import SupervisedModel

model = SupervisedModel(model_version="1.0.0")
model.train(
    X=train_features,
    y=train_labels,
    val_data=val_features,
    val_labels=val_labels,
)
```

### Mod√®le Non Supervis√© (IsolationForest)

**Dataset** : Payon Legit (transactions normales uniquement)

**Objectif** : D√©tecter les anomalies (patterns inconnus)

**Configuration par d√©faut** :
```python
{
    "contamination": 0.1,  # 10% d'anomalies attendues
    "random_state": 42,
    "n_estimators": 100,
}
```

**Calibration** : Scores bruts ‚Üí [0,1] via quantile mapping

**Code** : `src/models/unsupervised/train.py` ‚Üí `UnsupervisedModel`

**Exemple** :
```python
from src.models.unsupervised.train import UnsupervisedModel

model = UnsupervisedModel(model_version="1.0.0")
model.train(X=payon_legit_features)  # Pas de labels
```

---

## üìà √âtape 4 : Calibration des Seuils

Les seuils d√©terminent les d√©cisions finales (BLOCK/REVIEW/APPROVE).

**M√©thode** : Quantiles sur le validation set

```python
# Calculer les seuils
block_threshold = val_risk_scores.quantile(0.999)  # Top 0.1%
review_threshold = val_risk_scores.quantile(0.990)  # Top 1%
```

**V√©rification** :
- Recall fraude
- Precision sur BLOCK
- PR-AUC
- % BLOCK / % REVIEW

**Sauvegarde** : `thresholds.json` dans les artefacts

---

## üíæ √âtape 5 : Versioning et Sauvegarde

### Structure des Artefacts

```
artifacts/
‚îú‚îÄ‚îÄ v1.0.0/
‚îÇ   ‚îú‚îÄ‚îÄ supervised_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ unsupervised_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ feature_schema.json
‚îÇ   ‚îî‚îÄ‚îÄ thresholds.json
‚îî‚îÄ‚îÄ latest -> v1.0.0/
```

### Versioning SemVer

- **MAJOR** (2.0.0) : Changement majeur d'architecture
- **MINOR** (1.1.0) : Am√©lioration des hyperparam√®tres
- **PATCH** (1.0.1) : Correction de bugs

**Code** : `src/utils/versioning.py` ‚Üí `save_artifacts()`

---

## ‚òÅÔ∏è √âtape 6 : D√©ploiement sur Cloud Run Jobs

### Pr√©requis

1. **Google Cloud SDK install√©**
2. **Authentification** : `gcloud auth login`
3. **Projet configur√©** : `gcloud config set project sentinelle-485209`
4. **Donn√©es pr√©par√©es** : `Data/processed/*.csv`

### D√©ploiement

**Script automatique** :

```bash
./scripts/deploy-training-job.sh \
  "sentinelle-485209" \
  "sentinelle-training" \
  "europe-west1" \
  "1.0.0"
```

**Ce que fait le script** :
1. ‚úÖ Active les APIs n√©cessaires
2. ‚úÖ Cr√©e le bucket Cloud Storage (`sentinelle-485209-ml-data`)
3. ‚úÖ Upload les donn√©es vers Cloud Storage (~874 MB)
4. ‚úÖ Construit l'image Docker
5. ‚úÖ D√©ploie le job Cloud Run Jobs

**Temps** : ~5-10 minutes (premi√®re fois)

### Lancement

```bash
./scripts/run-training-cloud.sh \
  "sentinelle-485209" \
  "sentinelle-training" \
  "europe-west1" \
  "1.0.0"
```

**Temps d'ex√©cution** : ~30-45 minutes

### Suivi des Logs

```bash
# Logs en temps r√©el
gcloud run jobs logs read sentinelle-training \
  --region=europe-west1 \
  --project=sentinelle-485209 \
  --limit=100
```

### R√©cup√©ration des Artefacts

```bash
# T√©l√©charger depuis Cloud Storage
gsutil -m cp -r gs://sentinelle-485209-ml-data/artifacts/v1.0.0/ ./artifacts/
```

---

## ‚öôÔ∏è Ajustement des Param√®tres

### Hyperparam√®tres LightGBM

**Fichier** : `configs/model_config.yaml`

**Param√®tres principaux** :
- `num_leaves` : Complexit√© du mod√®le (d√©faut: 31)
- `learning_rate` : Vitesse d'apprentissage (d√©faut: 0.05)
- `n_estimators` : Nombre d'arbres (d√©faut: 1000)
- `scale_pos_weight` : Gestion du d√©s√©quilibre (auto)

**Modifier** :
```python
config = {
    "num_leaves": 63,  # Plus complexe
    "learning_rate": 0.01,  # Plus lent mais meilleur
}
model = SupervisedModel(config=config)
```

### Hyperparam√®tres IsolationForest

**Param√®tres principaux** :
- `contamination` : Proportion d'anomalies attendues (d√©faut: 0.1)
- `n_estimators` : Nombre d'arbres (d√©faut: 100)

**Modifier** :
```python
config = {
    "contamination": 0.05,  # Moins d'anomalies attendues
    "n_estimators": 200,  # Plus d'arbres
}
model = UnsupervisedModel(config=config)
```

### Ressources Cloud Run Jobs

**Modifier les ressources** :

```bash
gcloud run jobs update sentinelle-training \
  --region=europe-west1 \
  --cpu=16 \
  --memory=16Gi \
  --project=sentinelle-485209
```

**Plus de CPU = Plus rapide mais plus cher**

---

## üí∞ Co√ªts Estim√©s

**Par entra√Ænement** :
- **CPU** : 8 vCPU √ó 2700s √ó $0.00002400 = **$0.52**
- **RAM** : 8 GB √ó 2700s √ó $0.00000250 = **$0.05**
- **Storage** : N√©gligeable
- **Total** : **~$0.60 par entra√Ænement**

**Pour 10 entra√Ænements** : **~$6**

---

## üêõ D√©pannage

### Erreur : "Dataset PaySim non trouv√©"

**Solution** : V√©rifier que `Data/processed/paysim_mapped.csv` existe

```bash
ls -lh Data/processed/paysim_mapped.csv
```

### Erreur : "LEAKAGE TEMPOREL D√âTECT√â"

**Solution** : Le split temporel a d√©tect√© un probl√®me. V√©rifier les timestamps :

```python
# V√©rifier les timestamps
print(f"Train max: {train_df['created_at'].max()}")
print(f"Val min: {val_df['created_at'].min()}")
print(f"Val max: {val_df['created_at'].max()}")
print(f"Test min: {test_df['created_at'].min()}")
```

### Job Cloud Run √©choue

**Solution** : V√©rifier les logs

```bash
gcloud run jobs executions logs read <EXECUTION_NAME> \
  --region=europe-west1 \
  --project=sentinelle-485209
```

---

## üìö Pour Aller Plus Loin

### Pipeline Complet

Le script `scripts/train.py` orchestre tout le pipeline :

```python
# 1. Pr√©paration
train_df, val_df, test_df = prepare_training_data(...)

# 2. Feature Engineering
train_features = compute_features_parallel(train_df)
val_features = compute_features_parallel(val_df)

# 3. Entra√Ænement
supervised_model = train_supervised_model(train_features, train_labels)
unsupervised_model = train_unsupervised_model(payon_legit_features)

# 4. Calibration
thresholds = calibrate_thresholds(val_features, val_labels)

# 5. Sauvegarde
save_artifacts(version="1.0.0", artifacts={...})
```

### Workflow Complet

```
1. Pr√©parer les donn√©es (mapping PaySim)
   ‚Üì
2. Split temporel (70/15/15)
   ‚Üì
3. Calculer les features (parall√®le)
   ‚Üì
4. Entra√Æner LightGBM (supervis√©)
   ‚Üì
5. Entra√Æner IsolationForest (non supervis√©)
   ‚Üì
6. Calibrer les seuils
   ‚Üì
7. Sauvegarder les artefacts (versioning)
   ‚Üì
8. Upload vers Cloud Storage
```

---

## ‚úÖ Checklist

- [ ] Donn√©es pr√©par√©es (`paysim_mapped.csv`, `payon_legit_clean.csv`)
- [ ] Google Cloud SDK install√© et authentifi√©
- [ ] Projet GCP configur√©
- [ ] D√©ployer : `./scripts/deploy-training-job.sh`
- [ ] Lancer : `./scripts/run-training-cloud.sh`
- [ ] Suivre les logs
- [ ] R√©cup√©rer les artefacts depuis Cloud Storage

---

**Pr√™t √† entra√Æner ?** Lancez `./scripts/deploy-training-job.sh` ! üöÄ

