"""
Pipeline de pr√©paration des donn√©es pour l'entra√Ænement.

Ce module g√®re le split temporel, la validation, et la pr√©paration
des datasets pour l'entra√Ænement des mod√®les.
"""

from __future__ import annotations

from pathlib import Path
from typing import Tuple

import pandas as pd


def prepare_training_data(
    data_path: Path,
    train_ratio: float = 0.7,
    val_ratio: float = 0.15,
    test_ratio: float = 0.15,
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """
    Pr√©pare les donn√©es pour l'entra√Ænement avec split temporel.

    Args:
        data_path: Chemin vers le fichier de donn√©es nettoy√©es
        train_ratio: Proportion pour l'entra√Ænement (d√©faut: 0.7)
        val_ratio: Proportion pour la validation (d√©faut: 0.15)
        test_ratio: Proportion pour le test (d√©faut: 0.15)

    Returns:
        Tuple de (train_df, val_df, test_df)

    Raises:
        ValueError: Si les ratios ne somment pas √† 1.0
        FileNotFoundError: Si le fichier de donn√©es n'existe pas
    """
    # Validation des ratios
    if abs(train_ratio + val_ratio + test_ratio - 1.0) > 1e-6:
        raise ValueError(
            f"Les ratios doivent sommer √† 1.0, re√ßu: "
            f"train={train_ratio}, val={val_ratio}, test={test_ratio}"
        )

    # Charger les donn√©es
    if not data_path.exists():
        raise FileNotFoundError(f"Fichier de donn√©es non trouv√©: {data_path}")

    print(f"üìä Chargement des donn√©es depuis {data_path}...")
    df = pd.read_csv(data_path)

    print(f"   ‚úÖ {len(df)} transactions charg√©es")

    # Convertir created_at en datetime si ce n'est pas d√©j√† fait
    if "created_at" in df.columns:
        df["created_at"] = pd.to_datetime(df["created_at"], utc=True)
        # Trier par date pour le split temporel
        df = df.sort_values("created_at").reset_index(drop=True)
    else:
        raise ValueError("Colonne 'created_at' manquante dans les donn√©es")

    # Validation : v√©rifier qu'il n'y a pas de valeurs manquantes dans created_at
    if df["created_at"].isna().any():
        n_missing = df["created_at"].isna().sum()
        print(f"   ‚ö†Ô∏è  {n_missing} transactions avec created_at manquant, suppression...")
        df = df.dropna(subset=["created_at"])

    # Split temporel
    n_total = len(df)
    n_train = int(n_total * train_ratio)
    n_val = int(n_total * val_ratio)
    # Le reste va au test

    train_df = df.iloc[:n_train].copy()
    val_df = df.iloc[n_train : n_train + n_val].copy()
    test_df = df.iloc[n_train + n_val :].copy()

    print(f"\nüìä Split temporel:")
    print(f"   Train: {len(train_df)} transactions ({len(train_df)/n_total*100:.1f}%)")
    print(f"      P√©riode: {train_df['created_at'].min()} ‚Üí {train_df['created_at'].max()}")
    print(f"   Val:   {len(val_df)} transactions ({len(val_df)/n_total*100:.1f}%)")
    print(f"      P√©riode: {val_df['created_at'].min()} ‚Üí {val_df['created_at'].max()}")
    print(f"   Test:  {len(test_df)} transactions ({len(test_df)/n_total*100:.1f}%)")
    print(f"      P√©riode: {test_df['created_at'].min()} ‚Üí {test_df['created_at'].max()}")

    # Validation : v√©rifier qu'il n'y a pas de leakage temporel
    # On permet une √©galit√© exacte (fronti√®re) mais pas de chevauchement
    if len(train_df) > 0 and len(val_df) > 0:
        train_max = train_df["created_at"].max()
        val_min = val_df["created_at"].min()
        # V√©rifier qu'il n'y a pas de transactions du train apr√®s le d√©but de val
        # On permet l'√©galit√© car c'est la fronti√®re exacte du split
        if train_max > val_min:
            raise ValueError(
                "‚ö†Ô∏è  LEAKAGE TEMPOREL D√âTECT√â: "
                f"Train max ({train_max}) > Val min ({val_min})"
            )
        # V√©rifier qu'il n'y a pas de transactions du train dans val
        train_in_val = train_df[train_df["created_at"] == val_min]
        if len(train_in_val) > 0 and len(val_df[val_df["created_at"] == val_min]) > 0:
            # Il y a des transactions avec le m√™me timestamp dans train et val
            # C'est acceptable si c'est juste la fronti√®re, mais on v√©rifie qu'elles sont bien s√©par√©es
            pass  # Acceptable si c'est juste la fronti√®re

    if len(val_df) > 0 and len(test_df) > 0:
        val_max = val_df["created_at"].max()
        test_min = test_df["created_at"].min()
        if val_max > test_min:
            raise ValueError(
                "‚ö†Ô∏è  LEAKAGE TEMPOREL D√âTECT√â: "
                f"Val max ({val_max}) > Test min ({test_min})"
            )

    print("   ‚úÖ Aucun leakage temporel d√©tect√©")

    return train_df, val_df, test_df


def map_paysim_to_payon(
    paysim_path: Path,
    max_amount: float | None = None,
    output_path: Path | None = None,
) -> pd.DataFrame:
    """
    Mappe le dataset PaySim vers le format Payon.

    Mapping:
    - step ‚Üí created_at (step = heures depuis le d√©but, converti en timestamp)
    - type ‚Üí transaction_type
    - amount ‚Üí amount (filtr√© si max_amount sp√©cifi√©)
    - nameOrig ‚Üí source_wallet_id
    - nameDest ‚Üí destination_wallet_id
    - isFraud ‚Üí label (pour supervis√©)
    - Balances (oldbalanceOrg, etc.) ‚Üí IGNOR√âES (pas disponibles en prod)

    Args:
        paysim_path: Chemin vers le fichier PaySim CSV
        max_amount: Montant maximum autoris√© (None = pas de filtrage, recommand√© pour l'entra√Ænement)
        output_path: Chemin optionnel pour sauvegarder le r√©sultat

    Returns:
        DataFrame au format Payon
    """
    print(f"üìä Mapping PaySim ‚Üí Payon depuis {paysim_path}...")

    # Charger PaySim
    df = pd.read_csv(paysim_path)

    print(f"   ‚úÖ {len(df)} transactions PaySim charg√©es")

    # Filtrer les montants si max_amount est sp√©cifi√©
    if max_amount is not None:
        n_before = len(df)
        df = df[df["amount"] <= max_amount].copy()
        n_filtered = n_before - len(df)
        if n_filtered > 0:
            print(f"   ‚ö†Ô∏è  {n_filtered} transactions filtr√©es (amount > {max_amount})")
    else:
        print(f"   ‚ÑπÔ∏è  Aucun filtrage sur le montant (toutes les transactions conserv√©es)")

    # Mapping des colonnes
    payon_df = pd.DataFrame()

    # Identifiants
    payon_df["transaction_id"] = [f"paysim_{i}" for i in range(len(df))]
    payon_df["source_wallet_id"] = df["nameOrig"].astype(str)
    payon_df["destination_wallet_id"] = df["nameDest"].astype(str)

    # Montant
    payon_df["amount"] = df["amount"].astype(float)

    # Type de transaction
    payon_df["transaction_type"] = df["type"].astype(str)

    # Direction : d√©riv√©e du type PaySim
    # CASH_OUT, DEBIT, TRANSFER ‚Üí outgoing
    # CASH_IN, PAYMENT ‚Üí incoming (approximation)
    outgoing_types = {"CASH_OUT", "DEBIT", "TRANSFER"}
    payon_df["direction"] = df["type"].apply(
        lambda x: "outgoing" if x in outgoing_types else "incoming"
    )

    # Timestamp : step = heures depuis le d√©but
    # On cr√©e un timestamp de base et on ajoute les heures
    # Pour √©viter les doublons, on ajoute aussi des secondes bas√©es sur l'index
    base_timestamp = pd.Timestamp("2020-01-01 00:00:00", tz="UTC")
    # Cr√©er des timestamps uniques en ajoutant des secondes bas√©es sur l'index
    # On groupe par step et on ajoute des secondes incr√©mentales pour chaque transaction
    df_sorted = df.sort_values("step").reset_index(drop=True)
    df_sorted["step_rank"] = df_sorted.groupby("step").cumcount()
    payon_df["created_at"] = (
        base_timestamp
        + pd.to_timedelta(df_sorted["step"], unit="h")
        + pd.to_timedelta(df_sorted["step_rank"], unit="s")  # Ajouter des secondes pour diff√©rencier
    )

    # Currency : PaySim n'a pas de currency, on ajoute PYC
    payon_df["currency"] = "PYC"

    # Champs optionnels (vides pour PaySim)
    payon_df["provider"] = "PAYSIM"
    payon_df["provider_tx_id"] = None
    payon_df["initiator_user_id"] = payon_df["source_wallet_id"]  # Approximation
    payon_df["country"] = None
    payon_df["city"] = None
    payon_df["description"] = None

    # Label pour supervis√© (si pr√©sent)
    if "isFraud" in df.columns:
        payon_df["is_fraud"] = df["isFraud"].astype(int)
        print(f"   ‚úÖ Label 'is_fraud' ajout√© ({payon_df['is_fraud'].sum()} fraudes)")

    # Trier par created_at
    payon_df = payon_df.sort_values("created_at").reset_index(drop=True)

    print(f"   ‚úÖ {len(payon_df)} transactions mapp√©es au format Payon")

    # Sauvegarder si demand√©
    if output_path:
        payon_df.to_csv(output_path, index=False)
        print(f"   üíæ Sauvegard√© dans {output_path}")

    return payon_df
